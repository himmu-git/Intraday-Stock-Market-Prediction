# -*- coding: utf-8 -*-
"""final_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ClaCoQRLaalMtp9CM7WNjkT8IJ688Ij7
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Merge April, May, June 5-min Dataset

df0= pd.read_csv("TSLA_5min_April20.csv")
# flipping the data row-wise to arrange in ascending timeframe
df0=df0.sort_index(axis=0, ascending=False)
print(df0.shape)
print(df0)

df1= pd.read_csv("TSLA_5min_May20.csv")
df1=df1.sort_index(axis=0, ascending=False)
print(df1.shape)
print(df1)

df2= pd.read_csv("TSLA_5min_June20.csv")
df2=df2.sort_index(axis=0, ascending=False)
print(df2.shape)
print(df2)

df3= pd.read_csv("TSLA_5min_July20.csv")
df3=df3.sort_index(axis=0, ascending=False)
print(df3.shape)
print(df3)

df=pd.concat([df0,df1,df2,df3], ignore_index=True)
df_fig=df.copy(deep=True)
df[['Date', 'Time']]=df.time.str.split(expand=True)
df=df.drop(df.columns[0],axis=1)
df=df.drop(df.columns[5],axis=1)
timeList=np.array(df['Time'])
for i in range(len(timeList)):
    temp=timeList[i]
    temp=temp[:2]+temp[3:5]
    timeList[i]=int(temp)
print(timeList)
df['Time']=timeList
print(df)
print(df_fig)

import matplotlib.pyplot as plt

plt.plot(df_fig['time'], df_fig['close'])
plt.xlabel("Date")
plt.ylabel("Price ($)")
plt.title("Tesla Stock Price")
plt.plot()

plt.plot(df_fig['volume'])
plt.xlabel("Date")
plt.ylabel("Trading Volume")
plt.title("Tesla Stock Volume")
plt.plot()

print(df_fig['volume'])

# Calculate Average Price per instance
low_price=np.array(df['low'])
high_price=np.array(df['high'])
avg_price=[]
for low, high in zip(low_price, high_price):
    avg=(low+high)/2
    avg_price.append(round(avg,3))
print(len(avg_price))
df['Avg Price']=avg_price
print(df)

def buildSMA(price, gap):
    l=len(price)
    arr=np.zeros(l)
    for i in range(gap,l):
        arr[i]=sum(price[i-gap:i])/gap
        arr[i]=round(arr[i],3)
    return arr
def buildCross(lowMA,highMA):
    l=len(lowMA)
    arr=np.zeros(l)
    i=0
    for low_i, high_i in zip(lowMA,highMA):
        if low_i>high_i:
            #upward momentum (long signal)
            arr[i]=1
        elif low_i<high_i:
            #downward momentum (short signal)
            arr[i]=-1
        i+=1
    return arr
def addlabel(price):
    l=len(price)
    arr=np.zeros(l)
    for i in range(l-1):
        if price[i]<price[i+1]:
            arr[i]=1
    return arr

#%%
maList=[5,8,13,21,55,89,150,200]
# List of potential moving averages
for i in range(len(maList)):
    gap=maList[i]
    s=str(gap)+'-MA'
    df[s]=buildSMA(avg_price,gap)
print(df)


# Build MA Crossovers
count=0
for i in range(len(maList)):
    for j in range(i+1,len(maList)):
        count+=1
        s1=str(maList[i])+'-MA'
        s2=str(maList[j])+'-MA'
        s3=str(maList[i])+"/"+str(maList[j])+"Cross"
        lowMA=df[s1]
        highMA=df[s2]
        df[s3]=buildCross(lowMA,highMA)
print(df)
print(count)
df['label']=addlabel(avg_price)
df.to_csv("data.csv",index=False)

avg_price = np.array(df['Avg Price'])
df_=df
label=df_['label'].to_numpy()
df_=df_.drop(df_.columns[-1],axis=1)
data=df_.to_numpy()
print(data.shape, label.shape)
# print(data[6])

from sklearn.feature_selection import SelectFromModel
from sklearn.linear_model import Lasso, LogisticRegression
from sklearn import preprocessing
data = preprocessing.scale(data)
sel_ = SelectFromModel(LogisticRegression(C=1, penalty='l1', solver='liblinear'))
sel_.fit(data,label)
temp=sel_.get_support()
print('Feature Selection')
print(temp)

#print(data.shape)

def portfolio_evaluation(arr_pred, amount, price):
    arr_amount= []
    arr_nstock= []
    N= len(arr_pred)
    for i in range(N):
        if i==0:
            arr_amount.append(amount)    
        arr_amount.append(0)
        arr_nstock.append(0)
    state=0
    # state-> 0 (No Trading Position)
    # state-> 1 (Long Trading Position)
    # state-> -1 (Short Trading Position)
    for i in range(N):
        if state==0:
            if arr_pred[i]==1:
                # Open Long Position 
                if i==0:
                    temp_amount= arr_amount[i]
                    arr_amount[i]= 0
                    arr_nstock[i]= temp_amount/price[i]
                else:
                    arr_amount[i]= 0
                    arr_nstock[i]= arr_amount[i-1]/price[i]
                state=1
            else:
                # Open Short Position 
                if i==0:
                    arr_nstock[i]= -1*arr_amount[i]/price[i]
                    arr_amount[i]-= price[i]*arr_nstock[i]
                else:
                    arr_nstock[i]= -1*arr_amount[i-1]/price[i]
                    arr_amount[i]= arr_amount[i-1]-price[i]*arr_nstock[i]
                state=-1
        elif state==1 and arr_pred[i]==0:
            # Exit Long Position & Open Short Position
                temp_nstock=arr_nstock[i]
                arr_nstock[i]=0
                arr_amount[i]= price[i]*arr_nstock[i-1]+ arr_amount[i-1]
                # Short again
                arr_nstock[i]= -1*arr_amount[i]/price[i]
                arr_amount[i]= arr_amount[i-1]-price[i]*arr_nstock[i]
                state=-1
        elif state==-1 and arr_pred[i]==1:
            # Exit Short Position & Open Long Position
                temp_nstock=arr_nstock[i]
                arr_nstock[i]=0
                arr_amount[i]= price[i]*arr_nstock[i-1]+ arr_amount[i-1]
                # Long again
                arr_nstock[i]= arr_amount[i]/price[i]
                arr_amount[i]= 0
                state=1
    out=[]
    for i in range(N):
        out.append(arr_amount[i]+price[i]*arr_nstock[i])
    return out

from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn import svm

trainsize = int(data.shape[0]*0.70)

X_train = data[:trainsize,:]
X_test = data[trainsize:,:]

y_train = label[:trainsize]
y_test = label[trainsize:]


#print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)

clf = LogisticRegression()
clf.fit(X_train,y_train)
print('Logistic Regression')
print('Test:',clf.score(X_test, y_test))
print('Train:',clf.score(X_train, y_train))

print(confusion_matrix(y_test,clf.predict(X_test)))
print()

# print(portfolio_evaluation(clf.predict(X_test),1000,avg_price[trainsize:]))

clf = svm.SVC()
clf.fit(X_train,y_train)

print('SVM')
print('Test:',clf.score(X_test, y_test))
print('Train:',clf.score(X_train, y_train))
print(confusion_matrix(y_test,clf.predict(X_test)))

from sklearn.svm import LinearSVC

clf = svm.LinearSVC()
clf.fit(X_train,y_train)
print('Linear SVC')
print('Test:',clf.score(X_test, y_test))
print('Train:',clf.score(X_train, y_train))

print(confusion_matrix(y_test,clf.predict(X_test)))

from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn import svm

clf = svm.SVC(kernel = 'poly')
clf.fit(X_train,y_train)
print('Linear Poly')
print('Test:',clf.score(X_test, y_test))
print('Train:',clf.score(X_train, y_train))

print(confusion_matrix(y_test,clf.predict(X_test)))
print()

from sklearn.preprocessing import MinMaxScaler

# RNN Models

#LSTM Model

scaler = MinMaxScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
scaler.fit(X_test)
X_test = scaler.transform(X_test)
y_train = y_train.reshape(-1,1)
scaler.fit(y_train)
y_train = scaler.transform(y_train)
y_test = y_test.reshape(-1,1)
scaler.fit(y_test)
y_test = scaler.transform(y_test)

lb = 15

lstm_train_x = np.zeros(shape=(X_train.shape[0]-lb,lb,X_train.shape[1]))
lstm_train_y = np.zeros(shape=(y_train.shape[0]-lb))
lstm_test_x = np.zeros(shape=(X_test.shape[0]-lb,lb,X_test.shape[1]))
lstm_test_y = np.zeros(shape=(y_test.shape[0]-lb))
for ind in range(lstm_train_x.shape[0]):
    lstm_train_x[ind,:,:] = X_train[ind:ind+lb,:]
    lstm_train_y[ind] = y_train[ind+lb]
for ind in range(lstm_test_x.shape[0]):
    lstm_test_x[ind,:,:] = X_test[ind:ind+lb,:]
    lstm_test_y[ind] = y_test[ind+lb]

print(lstm_train_x.shape,lstm_test_x.shape)
print(lstm_train_y.shape,lstm_test_y.shape)

import tensorflow as tf
from keras.models import Sequential, Model
from keras.layers.recurrent import LSTM
from keras.layers.core import Dense,Dropout
from keras.callbacks import *

clf = Sequential()
clf.add(LSTM(units=150, input_shape=(lb,lstm_train_x.shape[2])))
clf.add(Dropout(0.2))
clf.add(Dense(units = 1))

clf.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),loss = 'binary_crossentropy', metrics = 'accuracy')
clf.fit(lstm_train_x,lstm_train_y, epochs = 100, batch_size = 100, callbacks = EarlyStopping(monitor='loss', mode = 'min'))

test_loss, test_acc = clf.evaluate(lstm_test_x,lstm_test_y)
train_loss, train_acc = clf.evaluate(lstm_train_x,lstm_train_y)
print("Single Layer LSTM")
print("Train accuracy", train_acc)
print("Test accuracy", test_acc)

clf = Sequential()
clf.add(LSTM(units=150,return_sequences = True, input_shape=(lb,lstm_train_x.shape[2])))
clf.add(Dropout(0.3))
clf.add(Activation('relu'))
clf.add(LSTM(units=100, return_sequences = True))
clf.add(Dropout(0.3))
clf.add(Activation('relu'))
clf.add(LSTM(units=100))
clf.add(Dropout(0.3))
clf.add(Dense(units = 1))
clf.add(Activation('relu'))

clf.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),loss = 'binary_crossentropy',metrics = 'accuracy')
clf.fit(lstm_train_x,lstm_train_y, epochs = 100, batch_size = 100, callbacks = EarlyStopping(monitor='loss', mode = 'min'))

test_loss, test_acc = clf.evaluate(lstm_test_x,lstm_test_y)
train_loss, train_acc = clf.evaluate(lstm_train_x,lstm_train_y)
print("Multi Layer LSTM")
print("Train accuracy", train_acc)
print("Test accuracy", test_acc)

from keras.layers.recurrent import GRU
clf = Sequential()
clf.add(GRU(units=150, input_shape=(lb, lstm_train_x.shape[2])))
clf.add(Dense(units = 1))
clf.add(Activation('sigmoid'))
clf.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),loss = 'binary_crossentropy', metrics = 'accuracy')
clf.fit(lstm_train_x,lstm_train_y, epochs = 100, batch_size = 100,callbacks = EarlyStopping(monitor='loss', mode = 'min'))
test_loss, test_acc = clf.evaluate(lstm_test_x,lstm_test_y)
train_loss, train_acc = clf.evaluate(lstm_train_x,lstm_train_y)
print("GRU :")
print("Train accuracy", train_acc)
print("Test accuracy", test_acc)